<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Voice AI (Patient)</title>
    <style>
        body { 
            font-family: 'Segoe UI', sans-serif; 
            background: #111; color: #fff; 
            display: flex; flex-direction: column; align-items: center; 
            height: 100vh; margin: 0; padding: 20px; box-sizing: border-box;
        }
        #chat-box { 
            width: 100%; max-width: 600px; flex-grow: 1; 
            background: #000; border: 1px solid #333; border-radius: 8px;
            overflow-y: auto; padding: 20px; margin-bottom: 20px;
            display: flex; flex-direction: column; gap: 12px;
        }
        .msg { padding: 10px 15px; border-radius: 10px; max-width: 80%; line-height: 1.4; }
        .msg.user { align-self: flex-end; background: #007bff; color: #fff; }
        .msg.ai { align-self: flex-start; background: #333; color: #eee; }
        .interim { opacity: 0.6; font-style: italic; }
        
        #controls { display: flex; gap: 15px; align-items: center;}
        button { 
            padding: 15px 30px; font-size: 1.1rem; cursor: pointer; 
            background: #28a745; color: white; border: none; border-radius: 50px; 
            transition: all 0.2s;
        }
        button:hover { transform: scale(1.05); }
        button.active { background: #dc3545; }
        .indicator { width: 12px; height: 12px; border-radius: 50%; background: #555; transition: 0.1s; }
        .indicator.on { background: #0f0; box-shadow: 0 0 10px #0f0; }
        .indicator.speaking { background: #007bff; box-shadow: 0 0 10px #007bff; }
    </style>
</head>
<body>
    <div id="chat-box"></div>

    <div id="controls">
        <div id="mic-indicator" class="indicator"></div>
        <button id="recordBtn">Start Conversation</button>
    </div>

    <script>
        const chatBox = document.getElementById('chat-box');
        const recordBtn = document.getElementById('recordBtn');
        const micIndicator = document.getElementById('mic-indicator');
        
        let socket;
        let audioContext;
        let nextStartTime = 0;
        let sourceNodes = [];
        let scriptProcessor;
        
        // --- CONFIG ---
        let aiIsSpeaking = false;
        
        // SENSITIVE GATE + STICKY MIC
        const NOISE_GATE = 0.01;     
        let silenceFrames = 0;
        const SILENCE_FRAME_THRESHOLD = 100; // ~2.5s hangover

        let currentInterimMsg = null; 
        let currentUserMsg = null;
        let currentAiMsg = null;

        recordBtn.addEventListener('click', async () => {
            if (audioContext && audioContext.state === 'running') {
                audioContext.close();
                if (socket) socket.close();
                recordBtn.innerText = "Start Conversation";
                recordBtn.classList.remove('active');
                micIndicator.classList.remove('on');
                return;
            }

            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            socket = new WebSocket(`ws://${window.location.host}`);
            
            socket.onopen = async () => {
                recordBtn.innerText = "Stop Conversation";
                recordBtn.classList.add('active');
                startMicrophone();
            };

            socket.onmessage = async (event) => {
                const msg = JSON.parse(event.data);

                if (msg.type === 'audio') {
                    playAudioChunk(msg.data);
                } 
                else if (msg.type === 'transcript') {
                    handleTranscript(msg);
                }
                else if (msg.type === 'response_complete') {
                    currentAiMsg = null; 
                }
            };
        });

        function handleTranscript(msg) {
            if (msg.sender === "user") {
                if (aiIsSpeaking) stopAllAudio(); 

                currentAiMsg = null;
                if (currentInterimMsg) { currentInterimMsg.remove(); currentInterimMsg = null; }

                if (msg.isFinal) {
                    if (currentUserMsg) {
                        currentUserMsg.innerText += " " + msg.text;
                    } else {
                        currentUserMsg = document.createElement('div');
                        currentUserMsg.className = "msg user";
                        currentUserMsg.innerText = msg.text;
                        chatBox.appendChild(currentUserMsg);
                    }
                } else {
                    currentInterimMsg = document.createElement('div');
                    currentInterimMsg.className = "msg user interim";
                    currentInterimMsg.innerText = msg.text + "...";
                    chatBox.appendChild(currentInterimMsg);
                }
            } 
            else if (msg.sender === "ai") {
                currentUserMsg = null; 
                if (!currentAiMsg) {
                    currentAiMsg = document.createElement('div');
                    currentAiMsg.className = "msg ai";
                    chatBox.appendChild(currentAiMsg);
                }
                currentAiMsg.innerText += msg.text;
            }
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        async function startMicrophone() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { sampleRate: 16000, echoCancellation: true, noiseSuppression: true }
                });
                
                const mic = audioContext.createMediaStreamSource(stream);
                scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                mic.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);

                scriptProcessor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    let sum = 0;
                    for(let i=0; i<inputData.length; i++) sum += inputData[i]*inputData[i];
                    const rms = Math.sqrt(sum/inputData.length);
                    
                    if (socket.readyState === WebSocket.OPEN) {
                        
                        if (aiIsSpeaking && rms > NOISE_GATE) {
                             stopAllAudio();
                             socket.send(JSON.stringify({ type: "interrupt_signal" }));
                             socket.send(convertFloat32ToInt16(inputData));
                             currentAiMsg = null;
                             return; 
                        }

                        if (rms > NOISE_GATE) {
                            silenceFrames = 0; 
                            micIndicator.classList.add('on');
                            socket.send(convertFloat32ToInt16(inputData));
                        } 
                        else {
                            silenceFrames++;
                            if (silenceFrames < SILENCE_FRAME_THRESHOLD) {
                                micIndicator.classList.add('on'); 
                                socket.send(convertFloat32ToInt16(inputData));
                            } else {
                                micIndicator.classList.remove('on');
                                socket.send(new Int16Array(inputData.length).fill(0).buffer);
                            }
                        }
                    }
                };
            } catch(e) {
                console.error("Mic Error", e);
            }
        }

        function convertFloat32ToInt16(float32) {
            const int16 = new Int16Array(float32.length);
            for(let i=0; i<float32.length; i++) {
                let s = Math.max(-1, Math.min(1, float32[i]));
                int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16.buffer;
        }

        function playAudioChunk(base64) {
            currentUserMsg = null;
            aiIsSpeaking = true;
            micIndicator.classList.add('speaking'); 

            const binary = atob(base64);
            const len = binary.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binary.charCodeAt(i);
            
            const int16 = new Int16Array(bytes.buffer);
            const float32 = new Float32Array(int16.length);
            for(let i=0; i<int16.length; i++) float32[i] = int16[i] / 32768.0;

            const buffer = audioContext.createBuffer(1, float32.length, 16000);
            buffer.getChannelData(0).set(float32);

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            
            if (nextStartTime < audioContext.currentTime) nextStartTime = audioContext.currentTime;
            
            source.start(nextStartTime);
            nextStartTime += buffer.duration;
            sourceNodes.push(source);
            
            source.onended = () => {
                const index = sourceNodes.indexOf(source);
                if (index > -1) sourceNodes.splice(index, 1);
                if (sourceNodes.length === 0) {
                    aiIsSpeaking = false;
                    micIndicator.classList.remove('speaking');
                }
            }
        }

        async function stopAllAudio() {
            sourceNodes.forEach(node => { try { node.stop(); } catch(e) {} });
            sourceNodes = [];
            
            if (audioContext.state === 'running') {
                await audioContext.suspend();
                await audioContext.resume();
            }
            nextStartTime = audioContext.currentTime;
            aiIsSpeaking = false;
            micIndicator.classList.remove('speaking');
        }
    </script>
</body>
</html>