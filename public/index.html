<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Voice AI (Patient) - Smooth Playback</title>
    <style>
        body { 
            font-family: 'Segoe UI', sans-serif; 
            background: #111; color: #fff; 
            display: flex; flex-direction: column; align-items: center; 
            height: 100vh; margin: 0; padding: 20px; box-sizing: border-box;
        }
        #chat-box { 
            width: 100%; max-width: 600px; flex-grow: 1; 
            background: #000; border: 1px solid #333; border-radius: 8px;
            overflow-y: auto; padding: 20px; margin-bottom: 20px;
            display: flex; flex-direction: column; gap: 12px;
        }
        .msg { padding: 10px 15px; border-radius: 10px; max-width: 80%; line-height: 1.4; }
        .msg.user { align-self: flex-end; background: #007bff; color: #fff; }
        .msg.ai { align-self: flex-start; background: #333; color: #eee; }
        .interim { opacity: 0.6; font-style: italic; }
        
        #controls { display: flex; gap: 15px; align-items: center;}
        button { 
            padding: 15px 30px; font-size: 1.1rem; cursor: pointer; 
            background: #28a745; color: white; border: none; border-radius: 50px; 
            transition: all 0.2s;
        }
        button:hover { transform: scale(1.05); }
        button.active { background: #dc3545; }
        .indicator { width: 12px; height: 12px; border-radius: 50%; background: #555; transition: 0.1s; }
        .indicator.on { background: #0f0; box-shadow: 0 0 10px #0f0; }
        .indicator.speaking { background: #007bff; box-shadow: 0 0 10px #007bff; }
    </style>
</head>
<body>
    <div id="chat-box"></div>
    <div id="controls">
        <div id="mic-indicator" class="indicator"></div>
        <button id="recordBtn">Start Conversation</button>
    </div>

    <script>
        const chatBox = document.getElementById('chat-box');
        const recordBtn = document.getElementById('recordBtn');
        const micIndicator = document.getElementById('mic-indicator');
        
        let socket;
        let audioContext;
        let nextStartTime = 0;
        let sourceNodes = [];
        let scriptProcessor;
        let aiIsSpeaking = false;

        // --- CONFIG ---
        const NOISE_GATE = 0.05;     
        let silenceFrames = 0;
        const SILENCE_FRAME_THRESHOLD = 80; 

        let currentInterimMsg = null; 
        let currentUserMsg = null;
        let currentAiMsg = null;

        recordBtn.addEventListener('click', async () => {
            if (audioContext && audioContext.state === 'running') {
                stopSession();
                return;
            }

            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            socket = new WebSocket(`ws://${window.location.host}`);
            
            socket.onopen = () => {
                console.log("[Socket] Connected");
                recordBtn.innerText = "Stop Conversation";
                recordBtn.classList.add('active');
                startMicrophone();
            };

            socket.onmessage = async (event) => {
                const msg = JSON.parse(event.data);
                if (msg.type === 'audio') {
                    playAudioChunk(msg.data);
                } else if (msg.type === 'transcript') {
                    handleTranscript(msg);
                } else if (msg.type === 'response_complete') {
                    currentAiMsg = null; 
                }
            };

            socket.onclose = () => stopSession();
        });

        function stopSession() {
            if (audioContext) audioContext.close();
            if (socket) socket.close();
            recordBtn.innerText = "Start Conversation";
            recordBtn.classList.remove('active');
            micIndicator.className = "indicator";
        }

        function handleTranscript(msg) {
            if (msg.sender === "user") {
                if (aiIsSpeaking) stopAllAudio(); 
                currentAiMsg = null;
                if (currentInterimMsg) { currentInterimMsg.remove(); currentInterimMsg = null; }

                if (msg.isFinal) {
                    if (currentUserMsg) {
                        currentUserMsg.innerText += " " + msg.text;
                    } else {
                        currentUserMsg = document.createElement('div');
                        currentUserMsg.className = "msg user";
                        currentUserMsg.innerText = msg.text;
                        chatBox.appendChild(currentUserMsg);
                    }
                } else {
                    currentInterimMsg = document.createElement('div');
                    currentInterimMsg.className = "msg user interim";
                    currentInterimMsg.innerText = msg.text + "...";
                    chatBox.appendChild(currentInterimMsg);
                }
            } else if (msg.sender === "ai") {
                currentUserMsg = null; 
                if (!currentAiMsg) {
                    currentAiMsg = document.createElement('div');
                    currentAiMsg.className = "msg ai";
                    chatBox.appendChild(currentAiMsg);
                }
                currentAiMsg.innerText += msg.text;
            }
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        async function startMicrophone() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { sampleRate: 16000, echoCancellation: true, noiseSuppression: true }
                });
                const mic = audioContext.createMediaStreamSource(stream);
                scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                mic.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);

                scriptProcessor.onaudioprocess = (e) => {
                    if (!socket || socket.readyState !== WebSocket.OPEN) return;
                    const inputData = e.inputBuffer.getChannelData(0);
                    let sum = 0;
                    for(let i=0; i<inputData.length; i++) sum += inputData[i]*inputData[i];
                    const rms = Math.sqrt(sum/inputData.length);
                    
                    // Adaptive Noise Gate: Ignore AI echo
                    const activeGate = aiIsSpeaking ? NOISE_GATE * 2.2 : NOISE_GATE;

                    if (rms > activeGate) {
                        if (aiIsSpeaking) {
                            console.log("[Interrupt] Stopping AI playback");
                            stopAllAudio();
                            socket.send(JSON.stringify({ type: "interrupt_signal" }));
                        }
                        silenceFrames = 0; 
                        micIndicator.classList.add('on');
                        socket.send(convertFloat32ToInt16(inputData));
                    } else {
                        silenceFrames++;
                        if (silenceFrames < SILENCE_FRAME_THRESHOLD) {
                            socket.send(convertFloat32ToInt16(inputData));
                        } else {
                            micIndicator.classList.remove('on');
                            socket.send(new Int16Array(inputData.length).fill(0).buffer);
                        }
                    }
                };
            } catch(e) { console.error("Mic Error", e); }
        }

        function convertFloat32ToInt16(float32) {
            const int16 = new Int16Array(float32.length);
            for(let i=0; i<float32.length; i++) {
                let s = Math.max(-1, Math.min(1, float32[i]));
                int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16.buffer;
        }

        function playAudioChunk(base64) {
            aiIsSpeaking = true;
            micIndicator.classList.add('speaking'); 

            const binary = atob(base64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
            
            const int16 = new Int16Array(bytes.buffer);
            const float32 = new Float32Array(int16.length);
            for(let i=0; i<int16.length; i++) float32[i] = int16[i] / 32768.0;

            const buffer = audioContext.createBuffer(1, float32.length, 16000);
            buffer.getChannelData(0).set(float32);

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            
            const now = audioContext.currentTime;
            
            // JITTER BUFFER: 200ms look-ahead to handle network bursts
            if (nextStartTime < now) {
                nextStartTime = now + 0.2; 
            }
            
            source.start(nextStartTime);
            nextStartTime += buffer.duration;
            sourceNodes.push(source);
            
            source.onended = () => {
                const index = sourceNodes.indexOf(source);
                if (index > -1) sourceNodes.splice(index, 1);
                if (sourceNodes.length === 0) {
                    aiIsSpeaking = false;
                    micIndicator.classList.remove('speaking');
                }
            }
        }

        async function stopAllAudio() {
            sourceNodes.forEach(node => { try { node.stop(); } catch(e) {} });
            sourceNodes = [];
            nextStartTime = 0;
            aiIsSpeaking = false;
            micIndicator.classList.remove('speaking');
        }
    </script>
</body>
</html>